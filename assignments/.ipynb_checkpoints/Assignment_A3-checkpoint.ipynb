{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment A3: Embeddings and Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covering material from notebooks 7 and 8 \n",
    "\n",
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training word2vec**\n",
    "\n",
    "In this section, we train a word2vec model using gensim. We train the model on text8 (which consists of the first 90M characters of a Wikipedia dump from 2006 and is considered one of the benchmarks for evaluating language models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "api.info(\"text8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = api.load(\"text8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "##TODO train a word2vec model on this dataset, only consider words which appear at least 10 times in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Similarities**\n",
    "\n",
    "gensim models provide almost all the utility you might want to wish for to perform standard word similarity tasks. They are available in the .wv (wordvectors) attribute of the model, more details could be found [here](https://radimrehurek.com/gensim/models/keyedvectors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv\n",
    "\n",
    "##TODO find the closest words to king"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "King is to man as woman is to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO find the closest word for the vector \"woman\" + \"king\" - \"man\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Word Similarities** \n",
    "\n",
    "One common way to evaluate word2vec models are word analogy tasks. Let's check how good our model is on one of those. We consider the [WordSim353](http://alfonseca.org/eng/research/wordsim353.html) benchmark, the task is to determine how similar two words are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
    "!tar xf ws353simrel.tar.gz\n",
    "\n",
    "path = \"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n",
    "\n",
    "def load_data(path):\n",
    "    X, y = [], []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            X.append((line[0], line[1])) # each entry in x contains two words, e.g. X[0] = (tiger, cat)\n",
    "            y.append(float(line[-1])) # each entry in y is the annotation how similar two words are, e.g. Y[0] = 7.35\n",
    "    return X, y\n",
    "\n",
    "X, y = load_data(path)\n",
    "print (X[:3], y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO compute how similar the pairs in the WordSim353 are according to our model\n",
    "##TODO if  aword is not present in our model, we assign similarity 0 for the respective text pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "##TODO compute spearman's rank correlation between our prediction and the human annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "en = spacy.load('en_core_web_md')\n",
    "\n",
    "##TODO compute word similarities in the WordSim353 dataset using spaCy word embeddings\n",
    "##TODO compute spearman's rank correlation between these similarities and the human annotations\n",
    "# Don't worry if results are not too convincing for this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "In this task, we evaluate different document embeddings on the English version of the [STS Benchmark](https://arxiv.org/pdf/1708.00055.pdf). The task is to determine how semantically similar two texts are and is a popular dataset to evaluate document embeddings, i.e. we want embeddings of two semantically similar documents to be similar as well. We provide a wordcounts baseline for this task and ask you to compute and evaluate embeddings for a selected sample of document embedding techniques.\n",
    "\n",
    "To evaluate, we follow [(Reimers and Gurevych, 2019)](https://arxiv.org/pdf/1908.10084.pdf) and compute the Spearmanâ€™s rank correlation between the cosine-similarity of thesentence embeddings and the gold labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the data\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
    "\n",
    "!unzip sts2017.eval.v1.1.zip \n",
    "!unzip sts2017.gs.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "def load_STS_data():\n",
    "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
    "        labels = [float(line.strip()) for line in f]\n",
    "    \n",
    "    text_a, text_b = [], []\n",
    "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            text_a.append(line[0])\n",
    "            text_b.append(line[1])\n",
    "    return text_a, text_b, labels\n",
    "\n",
    "text_a, text_b, labels = load_STS_data()\n",
    "text_a[0], text_b[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils\n",
    "from scipy.stats import spearmanr\n",
    "def evaluate(predictions, labels):\n",
    "    print (\"spearman's rank correlation\", spearmanr(predictions, labels)[0])\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcounts baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(text_a + text_b)\n",
    "\n",
    "# encode documents\n",
    "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
    "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
    "\n",
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO train Doc2Vec on the texts in the dataset\n",
    "##TODO derive the word vectors for each text in the dataset\n",
    "##TODO compute cosine similarity between the text pairs and evaluate spearman's rank correlation\n",
    "## Don't worry if results are not satisfactory using Doc2Vec (the dataset is too small to train good embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same with embeddings provided by spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same with universal sentence embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "Use your favorite document embeddings method to compute embeddings for a dataset you are interested in. Think of a method and provide some data visualization statistics (one method would be the path we have chosen in the notebook, i.e. cluster the embeddings with k-means and visualize low-dimensional representations of the document embeddings obtained by PCA). \n",
    "\n",
    "This task is very open and there is no right or wrong; If you want to use document embeddings in your course project, this is a chance to play around with them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110581</th>\n",
       "      <td>sport</td>\n",
       "      <td>UEFA to probe Valencia-Werder Bremen incidents</td>\n",
       "      <td>UEFA will be launching disciplinary proceeding...</td>\n",
       "      <td>UEFA to probe Valencia-Werder Bremen incidents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15925</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>New iMac tries to play it cool</td>\n",
       "      <td>Hot G5 chip requires some serious effort to av...</td>\n",
       "      <td>New iMac tries to play it cool Hot G5 chip req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46720</th>\n",
       "      <td>business</td>\n",
       "      <td>Ford Reports Disappointing U.S. Sales</td>\n",
       "      <td>Ford's car and truck business sales fell nearl...</td>\n",
       "      <td>Ford Reports Disappointing U.S. Sales Ford's c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57350</th>\n",
       "      <td>sci/tech</td>\n",
       "      <td>Microsoft Upgrades Windows XP Media Center (Ne...</td>\n",
       "      <td>NewsFactor - Bill Gates is about to announce a...</td>\n",
       "      <td>Microsoft Upgrades Windows XP Media Center (Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90601</th>\n",
       "      <td>sport</td>\n",
       "      <td>Rams make statement they #39;re team to beat i...</td>\n",
       "      <td>ST. LOUIS -- When St. Louis coach Mike Martz l...</td>\n",
       "      <td>Rams make statement they #39;re team to beat i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                              title  \\\n",
       "110581     sport     UEFA to probe Valencia-Werder Bremen incidents   \n",
       "15925   sci/tech                     New iMac tries to play it cool   \n",
       "46720   business              Ford Reports Disappointing U.S. Sales   \n",
       "57350   sci/tech  Microsoft Upgrades Windows XP Media Center (Ne...   \n",
       "90601      sport  Rams make statement they #39;re team to beat i...   \n",
       "\n",
       "                                                     lead  \\\n",
       "110581  UEFA will be launching disciplinary proceeding...   \n",
       "15925   Hot G5 chip requires some serious effort to av...   \n",
       "46720   Ford's car and truck business sales fell nearl...   \n",
       "57350   NewsFactor - Bill Gates is about to announce a...   \n",
       "90601   ST. LOUIS -- When St. Louis coach Mike Martz l...   \n",
       "\n",
       "                                                     text  \n",
       "110581  UEFA to probe Valencia-Werder Bremen incidents...  \n",
       "15925   New iMac tries to play it cool Hot G5 chip req...  \n",
       "46720   Ford Reports Disappointing U.S. Sales Ford's c...  \n",
       "57350   Microsoft Upgrades Windows XP Media Center (Ne...  \n",
       "90601   Rams make statement they #39;re team to beat i...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000) # # only use 10K datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#TODO preprocess the corpus using spacy or load the pre-processed corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_verb_pairs(sent):\n",
    "    subjs = [w for w in sent if w.dep_ == \"nsubj\"]\n",
    "    pairs = [(w.lemma_.lower(), w.head.lemma_.lower()) for w in subjs]\n",
    "    return pairs\n",
    "##TODO extract the subject-verbs pairs and print the result for the first document\n",
    "\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "\n",
    "##TODO create a list ranking the most common pairs and print the first 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same for verbs-object pairs ('dobj')\n",
    "##TODO create a list ranking the most common pairs and print the first 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same for adjectives-nouns pairs ('amod')\n",
    "##TODO create a list ranking the most common pairs and print the first 10 items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring cross label dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO extract all the subject-verbs and verbs-object pairs for the verb \"win\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO for each label create a list ranking the most common subject-verbs pairs and one for the most common verbs-object pairs\n",
    "##TODO print the 10 most common pairs for each of the two lists for the labels \"sport\" and \"business\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
